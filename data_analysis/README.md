# Data Analysis Pipeline

This directory contains the complete data analysis and visualization pipeline for the BDD100K object detection dataset. It includes tools for parsing annotations, generating statistical reports, creating visualizations, and hosting an interactive dashboard.

## Overview

The pipeline performs the following structured tasks:
1.  **Parsing**: Reads raw BDD100K JSON files and converts them into structured Python objects.
2.  **Analysis**: Computes comprehensive statistics including class distribution, object sizes, and anomaly detection.
3.  **Visualization**: Generates high-quality static plots and annotated sample images.
4.  **Reporting**: Aggregates findings into a generic JSON report and an interactive Streamlit dashboard.

## Directory Structure

Files in this directory and their roles:

-   `analysis.py`: Main analysis script. Calculates metrics and detects anomalies (e.g., empty labels, tiny objects).
-   `dashboard.py`: Streamlit application for interactive exploration of the analysis results.
-   `parser.py`: Utility module defining data structures (`BoundingBox`, `ImageAnnotation`) and parsing logic.
-   `visualize.py`: Generates static plots (bar charts, heatmaps) and visualizes interesting sample images with metadata overlays.
-   `convert_to_yolo.py`: Helper script to convert BDD100K JSON annotations into YOLO-compatible `.txt` files.
-   `download_dataset.py`: Utility to download the dataset if not present locally.

## Usage Instructions

### 1. Run the Analysis
Execute the main analysis script to generate the statistics file (`analysis_results.json`).
```bash
python data_analysis/analysis.py
```
*   **Input**: `data/bdd100k/labels/` and `data/bdd100k/images/`
*   **Output**: `output-Data_Analysis/analysis_results.json`

### 2. Generate Visualizations
Create static plots and annotated sample images.
```bash
python data_analysis/visualize.py
```
*   **Output**: `output-Data_Analysis/visualizations/` and `output-Data_Analysis/interesting_samples/`

### 3. Launch Dashboard
Start the interactive dashboard to view the results in a browser.
```bash
streamlit run data_analysis/dashboard.py
```

### 4. Convert Labels (Optional)
If training a YOLO model, convert the labels to the required format.
```bash
python data_analysis/convert_to_yolo.py
```

## Dashboard Details

The interactive dashboard (`dashboard.py`) serves as the presentation layer for the analysis pipeline. It is built with **Streamlit** and visualizes the pre-computed artifacts.

### Architecture
The dashboard does not perform heavy computation on the fly. Instead, it reads:
1.  `analysis_results.json`: Statistics and metrics.
2.  `output-Data_Analysis/visualizations/`: Static plots generated by `visualize.py`.
3.  `runs-model/`: Training artifacts (metrics and curves) from the YOLOv11 training.
4.  `interesting_samples/`: Annotated sample images.

### Dashboard Tabs
The interface is organized into six tabs for structured exploration:

1.  **Overview & Metrics**: Executive summary displaying total image counts, disk vs. label discrepancies, and dataset health indicators (e.g., empty labels, tiny objects).
2.  **Data Tables**: Raw data inspection allowing users to view class distribution counts, ratios, and bounding box statistics (mean/median sizes).
3.  **Analysis Plots**: Displays high-quality static visualizations including class imbalance charts, heatmaps, and size distributions.
4.  **Attributes**: Analyzes BDD100K-specific metadata, showing statistics for Weather, Time of Day, and Scene Type, as well as occlusion/truncation rates.
5.  **Model Evaluation**: Automatically detects the latest YOLOv11 training run and displays its result csv metrics, training curves (F1, Precision-Recall), and validation prediction comparisons.
6.  **Sample Images**: A gallery of "interesting" edge cases (e.g., most crowded images, largest/smallest instances per class) with overlaid metadata.

## Outputs

The pipeline generates artifacts in the `output-Data_Analysis` directory (located in the project root):

-   **analysis_results.json**: Complete statistical record of the dataset.
-   **visualizations/**: Folder containing PNG plots of class distributions, bounding box sizes, and attribute statistics.
-   **interesting_samples/**: Folder containing specific images of interest (e.g., most crowded scenes, largest/smallest objects) with metadata overlays showing weather and time of day.

## Dependencies

The analysis tools rely on standard Python data science libraries:
-   `numpy` and `pandas` for data manipulation.
-   `matplotlib` and `seaborn` for plotting.
-   `streamlit` for the dashboard.
-   `Pillow` for image processing.

Ensure all dependencies are installed via the project's requirements file.



