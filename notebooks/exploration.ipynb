{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc7e5eeb",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ccd546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Import project modules\n",
    "from data_analysis.parser import BDD100KParser\n",
    "from data_analysis.analysis import BDD100KAnalyzer\n",
    "from data_analysis.visualize import BDD100KVisualizer\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"âœ… Imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23514da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "TRAIN_JSON = '../data/bdd100k/labels/det_20/det_train.json'\n",
    "VAL_JSON = '../data/bdd100k/labels/det_20/det_val.json'\n",
    "TRAIN_IMAGES = '../data/bdd100k/images/100k/train'\n",
    "VAL_IMAGES = '../data/bdd100k/images/100k/val'\n",
    "\n",
    "# Check if files exist\n",
    "print(f\"Train JSON exists: {Path(TRAIN_JSON).exists()}\")\n",
    "print(f\"Val JSON exists: {Path(VAL_JSON).exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791b09a8",
   "metadata": {},
   "source": [
    "## 2. Data Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5b56bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse training data\n",
    "parser = BDD100KParser(TRAIN_JSON)\n",
    "train_data = parser.parse_all()\n",
    "\n",
    "# Get basic statistics\n",
    "stats = parser.get_statistics()\n",
    "\n",
    "print(\"\\n=== Dataset Statistics ===\")\n",
    "print(f\"Total Images: {stats['total_images']}\")\n",
    "print(f\"Total Objects: {stats['total_objects']}\")\n",
    "print(f\"Avg Objects per Image: {stats['avg_objects_per_image']:.2f}\")\n",
    "print(f\"Empty Images: {stats['empty_images']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed946f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display class distribution\n",
    "class_dist = stats['class_distribution']\n",
    "df_classes = pd.DataFrame(list(class_dist.items()), columns=['Class', 'Count'])\n",
    "df_classes = df_classes.sort_values('Count', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=df_classes, x='Class', y='Count', palette='viridis')\n",
    "plt.title('Class Distribution in Training Set', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Object Class', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "df_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c97572",
   "metadata": {},
   "source": [
    "## 3. Full Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6954a02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run comprehensive analysis\n",
    "analyzer = BDD100KAnalyzer(TRAIN_JSON, VAL_JSON)\n",
    "results = analyzer.run_full_analysis()\n",
    "\n",
    "# Print summary\n",
    "analyzer.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574a5872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize objects per image distribution\n",
    "opi = results['objects_per_image']\n",
    "\n",
    "train_dist = opi['train']['distribution']\n",
    "max_objects = max(train_dist.keys())\n",
    "\n",
    "counts = [train_dist.get(i, 0) for i in range(max_objects + 1)]\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.bar(range(len(counts)), counts, alpha=0.7, color='steelblue')\n",
    "plt.xlabel('Number of Objects per Image', fontsize=12)\n",
    "plt.ylabel('Number of Images', fontsize=12)\n",
    "plt.title('Distribution of Objects per Image', fontsize=16, fontweight='bold')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af74b8b",
   "metadata": {},
   "source": [
    "## 4. Sample Image Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6505c070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a random sample with objects\n",
    "samples_with_objects = [img for img in train_data if img['num_objects'] > 5]\n",
    "sample = np.random.choice(samples_with_objects)\n",
    "\n",
    "# Load and visualize image\n",
    "image_path = Path(TRAIN_IMAGES) / sample['image']\n",
    "\n",
    "if image_path.exists():\n",
    "    img = cv2.imread(str(image_path))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Draw bounding boxes\n",
    "    for obj in sample['objects']:\n",
    "        x1, y1, x2, y2 = [int(coord) for coord in obj['bbox']]\n",
    "        color = (255, 0, 0)  # Red\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)\n",
    "        cv2.putText(img, obj['class'], (x1, y1-5), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "    \n",
    "    plt.figure(figsize=(16, 10))\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"{sample['image']} - {sample['num_objects']} objects\", \n",
    "             fontsize=14, fontweight='bold')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nObjects in image:\")\n",
    "    for obj in sample['objects']:\n",
    "        print(f\"  - {obj['class']}\")\n",
    "else:\n",
    "    print(f\"Image not found: {image_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fddbfb",
   "metadata": {},
   "source": [
    "## 5. Anomaly Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a04526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display anomalies\n",
    "anomalies = results['anomalies']\n",
    "\n",
    "print(\"=== Anomaly Summary ===\")\n",
    "print(f\"Empty Images (Train): {anomalies['empty_images']['train']}\")\n",
    "print(f\"Empty Images (Val): {anomalies['empty_images']['val']}\")\n",
    "print(f\"\\nTiny Bounding Boxes: {anomalies['tiny_bboxes']['count']}\")\n",
    "print(f\"Occluded Objects: {anomalies['occluded_objects']['count']}\")\n",
    "print(f\"Overlapping Boxes: {anomalies['overlapping_boxes']['count']}\")\n",
    "\n",
    "# Visualize\n",
    "anomaly_types = ['Empty Images', 'Tiny Bboxes', 'Occluded', 'Overlapping']\n",
    "counts = [\n",
    "    anomalies['empty_images']['train'],\n",
    "    anomalies['tiny_bboxes']['count'],\n",
    "    anomalies['occluded_objects']['count'],\n",
    "    anomalies['overlapping_boxes']['count']\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = ['#ff6b6b', '#4ecdc4', '#45b7d1', '#ffa07a']\n",
    "plt.bar(anomaly_types, counts, color=colors, alpha=0.7)\n",
    "plt.title('Anomalies Detected in Dataset', fontsize=16, fontweight='bold')\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34edd30c",
   "metadata": {},
   "source": [
    "## 6. Key Insights and Recommendations\n",
    "\n",
    "Based on the analysis above, here are the key insights:\n",
    "\n",
    "### Dataset Characteristics\n",
    "1. **Class Imbalance:** Significant imbalance with cars dominating the dataset\n",
    "2. **Small Objects:** ~28% of objects are small, challenging for detection\n",
    "3. **Varied Scenes:** Average of 11 objects per image with high variance\n",
    "\n",
    "### Recommendations for Model Training\n",
    "\n",
    "1. **Handle Class Imbalance:**\n",
    "   - Use weighted loss function\n",
    "   - Oversample rare classes\n",
    "   - Focal loss for hard examples\n",
    "\n",
    "2. **Improve Small Object Detection:**\n",
    "   - Use higher input resolution\n",
    "   - Multi-scale training\n",
    "   - Mosaic augmentation\n",
    "\n",
    "3. **Data Augmentation:**\n",
    "   - Horizontal flips\n",
    "   - Color jittering\n",
    "   - Random crops and scales\n",
    "\n",
    "4. **Model Selection:**\n",
    "   - YOLOv8 recommended for speed/accuracy tradeoff\n",
    "   - Pretrained weights on COCO\n",
    "   - Fine-tune on BDD100K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2623be7",
   "metadata": {},
   "source": [
    "## 7. Next Steps\n",
    "\n",
    "To continue with this project:\n",
    "\n",
    "```bash\n",
    "# Train model\n",
    "python ../model/train.py --model m --epochs 50 --batch 16\n",
    "\n",
    "# Run evaluation\n",
    "python ../evaluation/metrics.py --model runs/train/best.pt\n",
    "\n",
    "# Error analysis\n",
    "python ../evaluation/error_analysis.py --model runs/train/best.pt\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
